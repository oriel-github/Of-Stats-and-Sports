{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "nhl_pop = cities.set_index('Metropolitan area')[['Population (2016 est.)[8]','NHL']]\n",
    "nhl_pop['NHL'] = nhl_pop['NHL'].replace(\"—\", \"\").str.replace(\"\\[.*\\]\",\"\",regex=True)\n",
    "nhl_pop = nhl_pop[nhl_pop['NHL'].str.contains('\\w+')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "nhl = nhl_df[nhl_df['year'] == 2018]\n",
    "nhl = nhl.drop(nhl.index[nhl['team'].str.contains('Division')])\n",
    "nhl['team'] = nhl['team'].str.replace('*', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_team_names(string):\n",
    "    split = string.split(' ')\n",
    "    if len(split) > 1:\n",
    "        new_split = []\n",
    "        while split != []:\n",
    "            if split[0][-1] == 's': \n",
    "                new_split.append(split.pop(0))\n",
    "                if split == []: break\n",
    "            if split[0][-1] != 's': \n",
    "                if len(split) == 1: new_split.append(split.pop(0))\n",
    "                else: new_split.append(' '.join([split.pop(0), split.pop(0)]))\n",
    "        return new_split\n",
    "    else: return split\n",
    "\n",
    "def match_teams(region_team_string, team_to_match):\n",
    "    for region_team in split_team_names(region_team_string): \n",
    "        if region_team in team_to_match: return region_team\n",
    "\n",
    "def match_metro(row): return nhl_pop['NHL'].apply(lambda x: match_teams(x, row)).dropna().index[0]\n",
    "nhl['Metropolitan area'] = nhl['team'].apply(match_metro)\n",
    "nhl['W/L ratio'] = nhl['W'].apply(int) / (nhl['W'].apply(int) + nhl['L'].apply(int))\n",
    "city_ratios = nhl[['W/L ratio', 'Metropolitan area']].groupby('Metropolitan area').mean()\n",
    "nhl_pop = nhl_pop.merge(city_ratios, on='Metropolitan area')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def nhl_correlation(): \n",
    "    population_by_region = nhl_pop['Population (2016 est.)[8]'].apply(int) # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = nhl_pop['W/L ratio'] # pass in win/loss ratio from nhl_df in the same order as cities[\"Metropolitan area\"]\n",
    "    \n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q1: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q1: There should be 28 teams being analysed for NHL\"\n",
    "    \n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "52a581df513c71153e105b93764cda4b",
     "grade": true,
     "grade_id": "cell-ebe0b2dfe1067e63",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "988912cae4968d81473f46d783e79c16",
     "grade": false,
     "grade_id": "cell-cb964e690298b71d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 2\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **NBA** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9394222aafc8ccab0a228098ba0d6010",
     "grade": false,
     "grade_id": "cell-5a5f21279e3d3572",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.17657160252844617, 0.36874741604463)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def nba_correlation():\n",
    "    nba = nba_df[lambda x: x['year'] == 2018]\n",
    "    nba['team'] = nba['team'].str.replace('*', '').str.replace(\"\\(.*\\)\",\"\")\n",
    "    nba['W/L ratio'] = nba['W'].apply(int) / (nba['W'].apply(int) + nba['L'].apply(int))\n",
    "    \n",
    "    all_pop = cities.set_index('Metropolitan area')[['Population (2016 est.)[8]','NBA']]\n",
    "    all_pop['NBA'] = all_pop['NBA'].replace(\"—\", \"\").str.replace(\"\\[.*\\]\",\"\")\n",
    "    global nba_pop\n",
    "    nba_pop = all_pop[all_pop['NBA'].str.contains('\\w+')]\n",
    "    \n",
    "    def match_metro(row): return nba_pop['NBA'].apply(lambda x: match_teams(x, row)).dropna().index[0]\n",
    "    nba['Metropolitan area'] = nba['team'].apply(match_metro)\n",
    "    city_ratios = nba[['W/L ratio', 'Metropolitan area']].groupby('Metropolitan area').mean()\n",
    "    nba_pop = nba_pop.merge(city_ratios, on='Metropolitan area')\n",
    "    \n",
    "    population_by_region = nba_pop['Population (2016 est.)[8]'].apply(int) # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = nba_pop['W/L ratio'] # pass in win/loss ratio from nba_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q2: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 28, \"Q2: There should be 28 teams being analysed for NBA\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
    "\n",
    "\n",
    "nba_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbdeb8eb22f525a34c10dc8798324e42",
     "grade": true,
     "grade_id": "cell-e573b2b4a282b470",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a1a5809f675ca033086422007cd73bd",
     "grade": false,
     "grade_id": "cell-96e15e4335df78f4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 3\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **MLB** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "27e8c0da6c9fa0dffc10488314335b6c",
     "grade": false,
     "grade_id": "cell-33b00fc3f3467b0c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1500373747540949, 0.46442827201123393)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def mlb_correlation(): \n",
    "    mlb = mlb_df[lambda x: x['year'] == 2018]\n",
    "    mlb['W/L ratio'] = mlb['W-L%']\n",
    "        \n",
    "    all_pop = cities.set_index('Metropolitan area')[['Population (2016 est.)[8]','MLB']]\n",
    "    all_pop['MLB'] = all_pop['MLB'].replace(\"—\", \"\").str.replace(\"\\[.*\\]\",\"\")\n",
    "    global mlb_pop\n",
    "    mlb_pop = all_pop[all_pop['MLB'].str.contains('\\w+')]\n",
    "    \n",
    "    def match_metro(row): return mlb_pop['MLB'].apply(lambda x: match_teams(x, row)).dropna().index[0]\n",
    "    mlb['Metropolitan area'] = mlb['team'].apply(match_metro)\n",
    "    city_ratios = mlb[['W/L ratio', 'Metropolitan area']].groupby('Metropolitan area').mean()\n",
    "    mlb_pop = mlb_pop.merge(city_ratios, on='Metropolitan area')\n",
    "    \n",
    "    population_by_region = mlb_pop['Population (2016 est.)[8]'].apply(int) # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = mlb_pop['W/L ratio'] # pass in win/loss ratio from mlb_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q3: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 26, \"Q3: There should be 26 teams being analysed for MLB\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
    "\n",
    "mlb_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cda33b094ba19ccc37a481e0dd29e0bc",
     "grade": true,
     "grade_id": "cell-764d4476f425c5a2",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6977a6da9ed6d8b7a0b7e37bbeda709b",
     "grade": false,
     "grade_id": "cell-793df6c04dfb126e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 4\n",
    "For this question, calculate the win/loss ratio's correlation with the population of the city it is in for the **NFL** using **2018** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4914ad1e119278ec2bd567c52640b66",
     "grade": false,
     "grade_id": "cell-8ccebc209aeec8d9",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004922112149349414, 0.9797833458363694)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def nfl_correlation(): \n",
    "    nfl = nfl_df[lambda x: x['year'] == 2018]\n",
    "    nfl = nfl.drop(nfl.index[nfl['team'].str.contains('FC')])\n",
    "    nfl['team'] = nfl['team'].str.replace('[*+]', '')\n",
    "    nfl['W/L ratio'] = nfl['W'].apply(int) / (nfl['W'].apply(int) + nfl['L'].apply(int))\n",
    "    \n",
    "    all_pop = cities.set_index('Metropolitan area')[['Population (2016 est.)[8]','NFL']]\n",
    "    all_pop['NFL'] = all_pop['NFL'].str.replace(\"\\[.*\\]\",\"\")\n",
    "    global nfl_pop\n",
    "    nfl_pop = all_pop[all_pop['NFL'].str.contains('\\w+')]\n",
    "        \n",
    "    def match_metro(row): return nfl_pop['NFL'].apply(lambda x: match_teams(x, row)).dropna().index[0]\n",
    "    nfl['Metropolitan area'] = nfl['team'].apply(match_metro)\n",
    "    city_ratios = nfl[['W/L ratio', 'Metropolitan area']].groupby('Metropolitan area').mean()\n",
    "    nfl_pop = nfl_pop.merge(city_ratios, on='Metropolitan area')\n",
    "        \n",
    "    population_by_region = nfl_pop['Population (2016 est.)[8]'].apply(int) # pass in metropolitan area population from cities\n",
    "    win_loss_by_region = nfl_pop['W/L ratio'] # pass in win/loss ratio from nfl_df in the same order as cities[\"Metropolitan area\"]\n",
    "\n",
    "    assert len(population_by_region) == len(win_loss_by_region), \"Q4: Your lists must be the same length\"\n",
    "    assert len(population_by_region) == 29, \"Q4: There should be 29 teams being analysed for NFL\"\n",
    "\n",
    "    return stats.pearsonr(population_by_region, win_loss_by_region)[0]\n",
    "\n",
    "nfl_correlation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9415d6399aa49e3a1a60813afdefa3b",
     "grade": true,
     "grade_id": "cell-de7b148b9554dbda",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b02d5cd3273f561e4ae939bb2a41740c",
     "grade": false,
     "grade_id": "cell-97b49d8639e908c4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Question 5\n",
    "In this question I would like you to explore the hypothesis that **given that an area has two sports teams in different sports, those teams will perform the same within their respective sports**. How I would like to see this explored is with a series of paired t-tests (so use [`ttest_rel`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)) between all pairs of sports. Are there any sports where we can reject the null hypothesis? Again, average values where a sport has multiple teams in one region. Remember, you will only be including, for each sport, cities which have teams engaged in that sport, drop others as appropriate. This question is worth 20% of the grade for this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6d78c961eb66f8d8c81f06d33ae8f393",
     "grade": false,
     "grade_id": "cell-92f25f44b8d1179f",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NFL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NHL</th>\n",
       "      <th>MLB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NFL</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.941792</td>\n",
       "      <td>0.030883</td>\n",
       "      <td>0.802499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBA</th>\n",
       "      <td>0.941792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>0.951629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHL</th>\n",
       "      <td>0.030883</td>\n",
       "      <td>0.022297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLB</th>\n",
       "      <td>0.802499</td>\n",
       "      <td>0.951629</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NFL       NBA       NHL       MLB\n",
       "NFL       NaN  0.941792  0.030883  0.802499\n",
       "NBA  0.941792       NaN  0.022297  0.951629\n",
       "NHL  0.030883  0.022297       NaN  0.000703\n",
       "MLB  0.802499  0.951629  0.000703       NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import re\n",
    "\n",
    "mlb_df=pd.read_csv(\"assets/mlb.csv\")\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "cities=pd.read_html(\"assets/wikipedia_data.html\")[1]\n",
    "cities=cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "def sports_team_performance():\n",
    "    # Note: p_values is a full dataframe, so df.loc[\"NFL\",\"NBA\"] should be the same as df.loc[\"NBA\",\"NFL\"] and\n",
    "    # df.loc[\"NFL\",\"NFL\"] should return np.nan\n",
    "    sports = ['NFL', 'NBA', 'NHL', 'MLB']\n",
    "    p_values = pd.DataFrame({k:np.nan for k in sports}, index=sports)\n",
    "    \n",
    "    pairs = ['NFL_NBA', 'NFL_NHL', 'NFL_MLB', 'NBA_NHL', 'NBA_MLB', 'NHL_MLB']\n",
    "        \n",
    "    NFL_NBA = nfl_pop.merge(nba_pop, on='Metropolitan area')\n",
    "    NFL_NHL = nfl_pop.merge(nhl_pop, on='Metropolitan area')\n",
    "    NFL_MLB = nfl_pop.merge(mlb_pop, on='Metropolitan area')\n",
    "    NBA_NHL = nba_pop.merge(nhl_pop, on='Metropolitan area')\n",
    "    NBA_MLB = nba_pop.merge(mlb_pop, on='Metropolitan area')\n",
    "    NHL_MLB = nhl_pop.merge(mlb_pop, on='Metropolitan area')\n",
    "    \n",
    "    NFL_NBA_stat = stats.ttest_rel(NFL_NBA['W/L ratio_x'], NFL_NBA['W/L ratio_y'])\n",
    "    NFL_NHL_stat = stats.ttest_rel(NFL_NHL['W/L ratio_x'], NFL_NHL['W/L ratio_y'])\n",
    "    NFL_MLB_stat = stats.ttest_rel(NFL_MLB['W/L ratio_x'], NFL_MLB['W/L ratio_y'])\n",
    "    NBA_NHL_stat = stats.ttest_rel(NBA_NHL['W/L ratio_x'], NBA_NHL['W/L ratio_y'])\n",
    "    NBA_MLB_stat = stats.ttest_rel(NBA_MLB['W/L ratio_x'], NBA_MLB['W/L ratio_y'])\n",
    "    NHL_MLB_stat = stats.ttest_rel(NHL_MLB['W/L ratio_x'], NHL_MLB['W/L ratio_y'])\n",
    "    \n",
    "    p_values.loc[\"NFL\", \"NBA\"] = NFL_NBA_stat.pvalue\n",
    "    p_values.loc[\"NBA\", \"NFL\"] = NFL_NBA_stat.pvalue\n",
    "    p_values.loc[\"NFL\", \"NHL\"] = NFL_NHL_stat.pvalue\n",
    "    p_values.loc[\"NHL\", \"NFL\"] = NFL_NHL_stat.pvalue\n",
    "    p_values.loc[\"NFL\", \"MLB\"] = NFL_MLB_stat.pvalue\n",
    "    p_values.loc[\"MLB\", \"NFL\"] = NFL_MLB_stat.pvalue\n",
    "    p_values.loc[\"NBA\", \"NHL\"] = NBA_NHL_stat.pvalue\n",
    "    p_values.loc[\"NHL\", \"NBA\"] = NBA_NHL_stat.pvalue\n",
    "    p_values.loc[\"NBA\", \"MLB\"] = NBA_MLB_stat.pvalue\n",
    "    p_values.loc[\"MLB\", \"NBA\"] = NBA_MLB_stat.pvalue\n",
    "    p_values.loc[\"NHL\", \"MLB\"] = NHL_MLB_stat.pvalue\n",
    "    p_values.loc[\"MLB\", \"NHL\"] = NHL_MLB_stat.pvalue\n",
    "    \n",
    "    assert abs(p_values.loc[\"NBA\", \"NHL\"] - 0.02) <= 1e-2, \"The NBA-NHL p-value should be around 0.02\"\n",
    "    assert abs(p_values.loc[\"MLB\", \"NFL\"] - 0.80) <= 1e-2, \"The MLB-NFL p-value should be around 0.80\"\n",
    "    return p_values\n",
    "\n",
    "sports_team_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a596ab421a45cc01168d10e8fbb8f89",
     "grade": true,
     "grade_id": "cell-fb4b9cb5ff4570a6",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "etc_active_cell": 14,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
